{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beve0x/theGraphLLM/blob/main/TheGraph_LLM_PoC_k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TheGraph-LLM Demo**\n",
        "\n",
        "In the following notebook, we aim to show how we can create a conceptual pipeline of Data extraction via Graph, and use GPT to create a chatBot-like experience for blockchain data analytics.\n",
        "For the demo below, it is required to create an account (with a wallet) in TheGraph, and an account with OpenAI.\n",
        "\n",
        "---\n",
        "Use this notebook below to run the demo.\n"
      ],
      "metadata": {
        "id": "2E_Meq0xEzj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os"
      ],
      "metadata": {
        "id": "5dIBiU2us0eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TheGraph GatewayURL\n",
        "Add the Gateway URL here. This will need you to get a graphAPI key. For example, for https://thegraph.com/explorer/subgraphs/HUZDsRpEVP2AvzDCyzDHtdc64dyDxx8FQjzsmqSg4H3B?view=Overview&chain=arbitrum-one (The Substreams Uniswap v3 Ethereum), the url looks like the one shown in the cell below. Replace [api-key] with your TheGraph API key."
      ],
      "metadata": {
        "id": "tdfGrv9GEwkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://gateway-arbitrum.network.thegraph.com/api/[api-key]/subgraphs/id/HUZDsRpEVP2AvzDCyzDHtdc64dyDxx8FQjzsmqSg4H3B\""
      ],
      "metadata": {
        "id": "yNrW-O1ts7R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GraphQL Query\n",
        "\n",
        "You can modify the graphQL query below. To know the attributes, you can refer to the substream playground (Found in the explorer: https://thegraph.com/explorer/subgraphs/HUZDsRpEVP2AvzDCyzDHtdc64dyDxx8FQjzsmqSg4H3B?view=Playground&chain=arbitrum-one). The playground provides an explorer which has all the eligible attributes via which graphQL can run the query."
      ],
      "metadata": {
        "id": "c1J4oqx0IZTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "{\n",
        "  factories(first: 5) {\n",
        "    id\n",
        "    poolCount\n",
        "    txCount\n",
        "    totalVolumeUSD\n",
        "  }\n",
        "  bundles(first: 5) {\n",
        "    id\n",
        "    ethPriceUSD\n",
        "  }\n",
        "  tokens(first: 20) {\n",
        "    id\n",
        "    name\n",
        "  }\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ByCqyHalt-80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cells below run the GraphQL API. You can run them as is."
      ],
      "metadata": {
        "id": "n0ZA0FJXKVux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"query\": query\n",
        "}"
      ],
      "metadata": {
        "id": "iMj39g02uPV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    result = response.json()\n",
        "    print(result)\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}, {response.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PSEkyZ6ub1J",
        "outputId": "9afa2263-7927-4cc8-c44c-7b291ca78bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': {'factories': [{'id': '0x1F98431c8aD98523631AE4a59f267346ea31F984', 'poolCount': '18667', 'txCount': '44442309', 'totalVolumeUSD': '1238052823980.30305322304874176553'}], 'bundles': [{'id': '1', 'ethPriceUSD': '2413.689436074894154128756508889091'}], 'tokens': [{'id': '0x00000000000045166c45af0fc6e4cf31d9e14b9a', 'name': 'TopBidder'}, {'id': '0x0000000000004946c0e9f43f4dee607b0ef1fa1c', 'name': 'Chi Gastoken by 1inch'}, {'id': '0x0000000000071566c1cf5db929f8e2e2f5d57da8', 'name': 'UOU'}, {'id': '0x0000000000071821e8033345a7be174647be0706', 'name': 'Scry Protocol'}, {'id': '0x0000000000085d4780b73119b644ae5ecd22b376', 'name': 'TrueUSD'}, {'id': '0x0000000000095413afc295d19edeb1ad7b71c952', 'name': 'Tokenlon'}, {'id': '0x000000000075f13bcf2e6652e84821e8b544f6f9', 'name': 'Signet'}, {'id': '0x000000000ca5171087c18fb271ca844a2370fc0a', 'name': 'Merkle Network Token'}, {'id': '0x00000000441378008ea67f4284a57932b1c000a5', 'name': 'TrueGBP'}, {'id': '0x000000007a58f5f58e697e51ab0357bc9e260a04', 'name': 'Concave'}, {'id': '0x00000000a82b4758df44fcb124e26a9b441e59a0', 'name': 'Zenith'}, {'id': '0x00000000f9fd50c832d79facfe6f4e8ce90a5efb', 'name': 'Polygon Token'}, {'id': '0x00000000feb6a772307c6aa88ab9d57b209acb18', 'name': 'ԼІΝЕА'}, {'id': '0x00000006e55a9364b657e3b91cd0411b4fd11ac2', 'name': 'Adidas Originals Metaverse'}, {'id': '0x00000008ff6439f99a481bfbc401c2e525b9aaa8', 'name': 'Circle Coin'}, {'id': '0x0000000f8750fd622863f6b4075ddb0011dfc730', 'name': 'Manta Network'}, {'id': '0x000000e29fa2bd3e5c215ffc71aa66b29c9769a2', 'name': 'Ethereum Express'}, {'id': '0x0000031d92594ea49c11b95c2e437b32036c9872', 'name': 'Nike RTFKT Studios'}, {'id': '0x000075dc60ede898f11b0d5c6ca31d7a6d050eed', 'name': 'LOVE YOU'}, {'id': '0x0000852600ceb001e08e00bc008be620d60031f2', 'name': 'TrueHKD'}]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can visualize the results which have been extracted from the blockchain query. This data is then dumped locally in the notebooks temporary."
      ],
      "metadata": {
        "id": "hcnS9GrvKysW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result['data']"
      ],
      "metadata": {
        "id": "f_0Y4JFdukeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df80611-ccf1-4d15-fe0d-5bcf30d0049b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'factories': [{'id': '0x1F98431c8aD98523631AE4a59f267346ea31F984',\n",
              "   'poolCount': '18667',\n",
              "   'txCount': '44442309',\n",
              "   'totalVolumeUSD': '1238052823980.30305322304874176553'}],\n",
              " 'bundles': [{'id': '1',\n",
              "   'ethPriceUSD': '2413.689436074894154128756508889091'}],\n",
              " 'tokens': [{'id': '0x00000000000045166c45af0fc6e4cf31d9e14b9a',\n",
              "   'name': 'TopBidder'},\n",
              "  {'id': '0x0000000000004946c0e9f43f4dee607b0ef1fa1c',\n",
              "   'name': 'Chi Gastoken by 1inch'},\n",
              "  {'id': '0x0000000000071566c1cf5db929f8e2e2f5d57da8', 'name': 'UOU'},\n",
              "  {'id': '0x0000000000071821e8033345a7be174647be0706',\n",
              "   'name': 'Scry Protocol'},\n",
              "  {'id': '0x0000000000085d4780b73119b644ae5ecd22b376', 'name': 'TrueUSD'},\n",
              "  {'id': '0x0000000000095413afc295d19edeb1ad7b71c952', 'name': 'Tokenlon'},\n",
              "  {'id': '0x000000000075f13bcf2e6652e84821e8b544f6f9', 'name': 'Signet'},\n",
              "  {'id': '0x000000000ca5171087c18fb271ca844a2370fc0a',\n",
              "   'name': 'Merkle Network Token'},\n",
              "  {'id': '0x00000000441378008ea67f4284a57932b1c000a5', 'name': 'TrueGBP'},\n",
              "  {'id': '0x000000007a58f5f58e697e51ab0357bc9e260a04', 'name': 'Concave'},\n",
              "  {'id': '0x00000000a82b4758df44fcb124e26a9b441e59a0', 'name': 'Zenith'},\n",
              "  {'id': '0x00000000f9fd50c832d79facfe6f4e8ce90a5efb',\n",
              "   'name': 'Polygon Token'},\n",
              "  {'id': '0x00000000feb6a772307c6aa88ab9d57b209acb18', 'name': 'ԼІΝЕА'},\n",
              "  {'id': '0x00000006e55a9364b657e3b91cd0411b4fd11ac2',\n",
              "   'name': 'Adidas Originals Metaverse'},\n",
              "  {'id': '0x00000008ff6439f99a481bfbc401c2e525b9aaa8', 'name': 'Circle Coin'},\n",
              "  {'id': '0x0000000f8750fd622863f6b4075ddb0011dfc730',\n",
              "   'name': 'Manta Network'},\n",
              "  {'id': '0x000000e29fa2bd3e5c215ffc71aa66b29c9769a2',\n",
              "   'name': 'Ethereum Express'},\n",
              "  {'id': '0x0000031d92594ea49c11b95c2e437b32036c9872',\n",
              "   'name': 'Nike RTFKT Studios'},\n",
              "  {'id': '0x000075dc60ede898f11b0d5c6ca31d7a6d050eed', 'name': 'LOVE YOU'},\n",
              "  {'id': '0x0000852600ceb001e08e00bc008be620d60031f2', 'name': 'TrueHKD'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('data')\n",
        "file_path = \"data/result.txt\""
      ],
      "metadata": {
        "id": "ZBX0Jq17vw4i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "e05c1222-efd1-4e63-f158-50a054c09486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0e81e0a9e9a5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/result.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the response to a text file\n",
        "with open(file_path, 'w') as file:\n",
        "  file.write(str(result['data']))"
      ],
      "metadata": {
        "id": "t2Bu0UjexqSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install llama-index library. LlamaIndex is used to handle very large query texts, which may exceed the context length of GPT APIs"
      ],
      "metadata": {
        "id": "8AC4X-VVLPEn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9Q-94shoFd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71cbd66a-68e5-4bc5-90b4-0fd04a016d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.9.22-py3-none-any.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.12.2 (from llama-index)\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from llama-index)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n",
            "Collecting httpx (from llama-index)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\n",
            "Collecting openai>=1.1.0 (from llama-index)\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.5.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index) (1.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (4.66.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (1.3.0)\n",
            "Collecting typing-extensions>=4.5.0 (from llama-index)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx->llama-index)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (3.6)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2023.3.post1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Installing collected packages: typing-extensions, mypy-extensions, marshmallow, h11, deprecated, beautifulsoup4, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beautifulsoup4-4.12.2 dataclasses-json-0.6.3 deprecated-1.2.14 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 llama-index-0.9.22 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.6.1 tiktoken-0.5.2 typing-extensions-4.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI API\n",
        "\n",
        "Below cells are used to run OpenAI APIs via LLamaIndex. You will need the OpenAI API key. Fill your API key in the cell below instead of <your-openai-key>"
      ],
      "metadata": {
        "id": "e3uEqv-WLam6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY']='<your-openai-key>'"
      ],
      "metadata": {
        "id": "Ptmedwct1UFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "stAlImgz1bN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below, we have modified the GPT prompt, to add more context and help GPT for a better analysis. You can also make any changes if required. Consider this as the exact prompt which is fed into GPT."
      ],
      "metadata": {
        "id": "U0ynrbo2MmzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.prompts import PromptTemplate\n",
        "qa_prompt_tmpl_str = (\n",
        "    \"Context information is below. It is a json formatted data coming from a blockchain, queried from the uniswap substream.\\n\"\n",
        "    \"---------------------\\n\"\n",
        "    \"{context_str}\\n\"\n",
        "    \"---------------------\\n\"\n",
        "    \"Given the context information and no prior knowledge, \"\n",
        "    \"answer the query about the blockchain data.\\n\"\n",
        "    \"Query: {query_str}\\n\"\n",
        "    \"Answer: \"\n",
        ")\n",
        "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
        "query_engine = index.as_query_engine(response_mode=\"compact\")\n",
        "query_engine.update_prompts(\n",
        "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
        ")"
      ],
      "metadata": {
        "id": "uFsMmwcB4Vbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results\n",
        "\n",
        "Add your question in the question variable. Run the below cell to get the result."
      ],
      "metadata": {
        "id": "pMlspD5QNGUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#query_engine = index.as_query_engine()\n",
        "question = \"How many tokens are there?\"\n",
        "response = query_engine.query(question)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "9iwHWkB91mP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2cd50b-58ff-4fa7-a066-4f9a1a8aabe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 20 tokens in the blockchain data.\n"
          ]
        }
      ]
    }
  ]
}